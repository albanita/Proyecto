{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3XrDOihm4ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/albanita/Proyecto/blob/master/dataset.zip?raw=true -O dataset.zip\n",
        "!unzip dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WE2Bdy6m_F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np,sys,os\n",
        "from numpy import float32\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.ndimage import imread\n",
        "from scipy.misc import imresize\n",
        "\n",
        "np.random.seed(678)\n",
        "tf.set_random_seed(678)\n",
        "\n",
        "# Activation Functions - however there was no indication in the original paper\n",
        "def tf_Relu(x): return tf.nn.relu(x)\n",
        "def d_tf_Relu(x): return tf.cast(tf.greater(x,0),tf.float32)\n",
        "\n",
        "def tf_log(x): return tf.sigmoid(x)\n",
        "def d_tf_log(x): return tf_log(x) * (1.0 - tf.log(x))\n",
        "\n",
        "def tf_tanh(x): return tf.tanh(x)\n",
        "def d_tf_tanh(x): return 1.0 - tf.square(tf_tanh(x))\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    X = np.asarray(dict[b'data'].T).astype(\"uint8\")\n",
        "    Yraw = np.asarray(dict[b'labels'])\n",
        "    Y = np.zeros((10,10000))\n",
        "    for i in range(10000):\n",
        "        Y[Yraw[i],i] = 1\n",
        "    names = np.asarray(dict[b'filenames'])\n",
        "    return X,Y,names\n",
        "\n",
        "# make class \n",
        "class CNNLayer():\n",
        "    \n",
        "    def __init__(self,ker,in_c,out_c,act,d_act,):\n",
        "        \n",
        "        self.w = tf.Variable(tf.truncated_normal([ker,ker,in_c,out_c],stddev=0.005))\n",
        "        self.act,self.d_act = act,d_act\n",
        "        self.m,self.v = tf.Variable(tf.zeros_like(self.w)),tf.Variable(tf.zeros_like(self.w))\n",
        "\n",
        "    def feedforward(self,input,stride=1):\n",
        "        self.input  = input\n",
        "        self.layer  = tf.nn.conv2d(input,self.w,strides = [1,stride,stride,1],padding='SAME')\n",
        "        self.layerA = self.act(self.layer)\n",
        "        return self.layerA\n",
        "\n",
        "    def backprop(self,gradient,stride=1):\n",
        "        grad_part_1 = gradient\n",
        "        grad_part_2 = self.d_act(self.layer)\n",
        "        grad_part_3 = self.input\n",
        "\n",
        "        grad_middle = tf.multiply(grad_part_1,grad_part_2)\n",
        "        grad = tf.nn.conv2d_backprop_filter(\n",
        "            input = grad_part_3,filter_sizes = self.w.shape,\n",
        "            out_backprop = grad_middle,strides=[1,1,1,1], padding=\"SAME\"\n",
        "        )\n",
        "\n",
        "        grad_pass  = tf.nn.conv2d_backprop_input(\n",
        "            input_sizes=[batch_size] + list(self.input.shape[1:]),filter = self.w ,\n",
        "            out_backprop = grad_middle,strides=[1,1,1,1], padding=\"SAME\"\n",
        "        )\n",
        "\n",
        "        update_w = []\n",
        "\n",
        "        update_w.append(\n",
        "            tf.assign( self.m,self.m*beta_1 + (1-beta_1) * grad   )\n",
        "        )\n",
        "        update_w.append(\n",
        "            tf.assign( self.v,self.v*beta_2 + (1-beta_2) * grad ** 2   )\n",
        "        )\n",
        "\n",
        "        m_hat = self.m / (1-beta_1)\n",
        "        v_hat = self.v / (1-beta_2)\n",
        "        adam_middel = learing_rate/(tf.sqrt(v_hat) + adam_e)\n",
        "        update_w.append(tf.assign(self.w,tf.subtract(self.w,tf.multiply(adam_middel,m_hat))))\n",
        "\n",
        "        return grad_pass,update_w\n",
        "\n",
        "\n",
        "data_location = \"./big_image/\"\n",
        "data_array = []  # create an empty list\n",
        "for dirName, subdirList, fileList in sorted(os.walk(data_location)):\n",
        "    for filename in fileList:\n",
        "        if \".jpg\" in filename.lower():  # check whether the file's DICOM\n",
        "            data_array.append(os.path.join(dirName,filename))\n",
        "\n",
        "X = np.zeros(shape=(100,80,80,3))\n",
        "\n",
        "for file_index in range(len(data_array)):\n",
        "    X[file_index,:,:]   = imresize(imread(data_array[file_index],mode='RGB'),(80,80))\n",
        "\n",
        "X[:,:,:,0] = (X[:,:,:,0]-X[:,:,:,0].min(axis=0))/(X[:,:,:,0].max(axis=0)-X[:,:,:,0].min(axis=0))\n",
        "X[:,:,:,1] = (X[:,:,:,1]-X[:,:,:,1].min(axis=0))/(X[:,:,:,1].max(axis=0)-X[:,:,:,1].min(axis=0))\n",
        "X[:,:,:,2] = (X[:,:,:,2]-X[:,:,:,2].min(axis=0))/(X[:,:,:,2].max(axis=0)-X[:,:,:,2].min(axis=0))\n",
        "\n",
        "X = shuffle(X)\n",
        "s_images = X[:50,:,:,:]\n",
        "c_images = X[50:,:,:,:]\n",
        "\n",
        "# hyper\n",
        "num_epoch = 1000\n",
        "num_epoch = 30000\n",
        "\n",
        "learing_rate = 0.0001\n",
        "batch_size = 10\n",
        "\n",
        "networ_beta = 1.0\n",
        "\n",
        "beta_1,beta_2 = 0.9,0.999\n",
        "adam_e = 1e-8\n",
        "\n",
        "proportion_rate = 0.6\n",
        "decay_rate = 0.9\n",
        "\n",
        "# init class\n",
        "prep_net1 = CNNLayer(3,3,50,tf_Relu,d_tf_Relu)\n",
        "prep_net2 = CNNLayer(3,50,50,tf_Relu,d_tf_Relu)\n",
        "prep_net3 = CNNLayer(3,50,50,tf_Relu,d_tf_Relu)\n",
        "prep_net4 = CNNLayer(3,50,50,tf_Relu,d_tf_Relu)\n",
        "prep_net5 = CNNLayer(3,50,3,tf_Relu,d_tf_Relu)\n",
        "\n",
        "hide_net1 = CNNLayer(4,6,50,tf_Relu,d_tf_Relu)\n",
        "hide_net2 = CNNLayer(4,50,50,tf_Relu,d_tf_Relu)\n",
        "hide_net3 = CNNLayer(4,50,50,tf_Relu,d_tf_Relu)\n",
        "hide_net4 = CNNLayer(4,50,50,tf_Relu,d_tf_Relu)\n",
        "hide_net5 = CNNLayer(4,50,3,tf_Relu,d_tf_Relu)\n",
        "\n",
        "reve_net1 = CNNLayer(5,3,50,tf_Relu,d_tf_Relu)\n",
        "reve_net2 = CNNLayer(5,50,50,tf_Relu,d_tf_Relu)\n",
        "reve_net3 = CNNLayer(5,50,50,tf_Relu,d_tf_Relu)\n",
        "reve_net4 = CNNLayer(5,50,50,tf_Relu,d_tf_Relu)\n",
        "reve_net5 = CNNLayer(5,50,3,tf_Relu,d_tf_Relu)\n",
        "\n",
        "# make graph\n",
        "Secret = tf.placeholder(shape=[None,80,80,3],dtype=tf.float32)\n",
        "Cover = tf.placeholder(shape=[None,80,80,3],dtype=tf.float32)\n",
        "\n",
        "iter_variable_dil = tf.placeholder(tf.float32, shape=())\n",
        "decay_propotoin_rate = proportion_rate / (1 + decay_rate * iter_variable_dil)\n",
        "\n",
        "prep_layer1 = prep_net1.feedforward(Secret)\n",
        "prep_layer2 = prep_net2.feedforward(prep_layer1)\n",
        "prep_layer3 = prep_net3.feedforward(prep_layer2)\n",
        "prep_layer4 = prep_net4.feedforward(prep_layer3)\n",
        "prep_layer5 = prep_net5.feedforward(prep_layer4)\n",
        "\n",
        "hide_Input = tf.concat([Cover,prep_layer5],axis=3)\n",
        "hide_layer1 = hide_net1.feedforward(hide_Input)\n",
        "hide_layer2 = hide_net2.feedforward(hide_layer1)\n",
        "hide_layer3 = hide_net3.feedforward(hide_layer2)\n",
        "hide_layer4 = hide_net4.feedforward(hide_layer3)\n",
        "hide_layer5 = hide_net5.feedforward(hide_layer4)\n",
        "\n",
        "reve_layer1 = reve_net1.feedforward(hide_layer5)\n",
        "reve_layer2 = reve_net2.feedforward(reve_layer1)\n",
        "reve_layer3 = reve_net3.feedforward(reve_layer2)\n",
        "reve_layer4 = reve_net4.feedforward(reve_layer3)\n",
        "reve_layer5 = reve_net5.feedforward(reve_layer4)\n",
        "\n",
        "cost_1 = tf.reduce_mean(tf.square(hide_layer5 - Cover))*0.5\n",
        "cost_2 = tf.reduce_mean(tf.square(reve_layer5 - Secret)) *0.5\n",
        "\n",
        "# --- auto train ---\n",
        "# auto_train = tf.train.AdamOptimizer(learning_rate=learing_rate).minimize(cost_1+cost_2)\n",
        "\n",
        "reve_net_grad5,reve_net_grad5w = reve_net5.backprop(reve_layer5-Secret)\n",
        "reve_net_grad4,reve_net_grad4w = reve_net4.backprop(reve_net_grad5)\n",
        "reve_net_grad3,reve_net_grad3w = reve_net3.backprop(reve_net_grad4 + decay_propotoin_rate * (reve_net_grad5))\n",
        "reve_net_grad2,reve_net_grad2w = reve_net2.backprop(reve_net_grad3+ decay_propotoin_rate * (reve_net_grad5 + reve_net_grad4))\n",
        "reve_net_grad1,reve_net_grad1w = reve_net1.backprop(reve_net_grad2+ decay_propotoin_rate * (reve_net_grad5 + reve_net_grad4 + reve_net_grad3))\n",
        "\n",
        "hide_net_grad5,hide_net_grad5w = hide_net5.backprop( (hide_layer5-Cover) + reve_net_grad1 )\n",
        "hide_net_grad4,hide_net_grad4w = hide_net4.backprop(hide_net_grad5)\n",
        "hide_net_grad3,hide_net_grad3w = hide_net3.backprop(hide_net_grad4+ decay_propotoin_rate *(hide_net_grad5 ))\n",
        "hide_net_grad2,hide_net_grad2w = hide_net2.backprop(hide_net_grad3+ decay_propotoin_rate *(hide_net_grad5 + hide_net_grad4))\n",
        "hide_net_grad1,hide_net_grad1w = hide_net1.backprop(hide_net_grad2+ decay_propotoin_rate *(hide_net_grad5 + hide_net_grad4 + hide_net_grad3))\n",
        "\n",
        "prep_net_Input = hide_net_grad1[:,:,:,3:]\n",
        "prep_net_grad5,prep_net_grad5w = prep_net5.backprop(prep_net_Input)\n",
        "prep_net_grad4,prep_net_grad4w = prep_net4.backprop(prep_net_grad5)\n",
        "prep_net_grad3,prep_net_grad3w = prep_net3.backprop(prep_net_grad4+ decay_propotoin_rate *(prep_net_grad5))\n",
        "prep_net_grad2,prep_net_grad2w = prep_net2.backprop(prep_net_grad3+ decay_propotoin_rate *(prep_net_grad5 +prep_net_grad4 ))\n",
        "prep_net_grad1,prep_net_grad1w = prep_net1.backprop(prep_net_grad2+ decay_propotoin_rate *(prep_net_grad5 + prep_net_grad4 +prep_net_grad3 ))\n",
        "\n",
        "grad_update = reve_net_grad5w + reve_net_grad4w + reve_net_grad3w + reve_net_grad2w + reve_net_grad1w + \\\n",
        "                hide_net_grad5w + hide_net_grad4w + hide_net_grad3w + hide_net_grad2w + hide_net_grad1w + \\\n",
        "                prep_net_grad5w + prep_net_grad4w + prep_net_grad3w + prep_net_grad2w + prep_net_grad1w\n",
        "\n",
        "\n",
        "# start the session\n",
        "with tf.Session() as sess : \n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for iter in range(num_epoch):\n",
        "        for current_batch_index in range(0,len(s_images),batch_size):\n",
        "            current_batch_s = s_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
        "            current_batch_c = c_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n",
        "            sess_results = sess.run([cost_1,cost_2,grad_update],feed_dict={Secret:current_batch_s,Cover:current_batch_c,iter_variable_dil:iter})\n",
        "            print(\"Iter: \",iter, ' cost 1: ',sess_results[0],' cost 2: ',sess_results[1],end='\\r')\n",
        "\n",
        "        if iter % 100 == 0 :\n",
        "            random_data_index = np.random.randint(len(s_images))\n",
        "            current_batch_s = np.expand_dims(s_images[random_data_index,:,:,:],0)\n",
        "            current_batch_c = np.expand_dims(c_images[random_data_index,:,:,:],0)\n",
        "            sess_results = sess.run([prep_layer5,hide_layer5,reve_layer5],feed_dict={Secret:current_batch_s,Cover:current_batch_c})\n",
        "\n",
        "            plt.figure()\n",
        "            plt.imshow(np.squeeze(current_batch_s[0,:,:,:]))\n",
        "            plt.axis('off')\n",
        "            plt.title('epoch_'+str(iter)+' Secret')\n",
        "            plt.savefig('images/epoch_'+str(iter)+\"a_secret.png\")\n",
        "\n",
        "            plt.figure()\n",
        "            plt.imshow(np.squeeze(current_batch_c[0,:,:,:]))\n",
        "            plt.axis('off')\n",
        "            plt.title('epoch_'+str(iter)+' cover')\n",
        "            plt.savefig('images/epoch_'+str(iter)+\"b_cover.png\")\n",
        "\n",
        "            plt.figure()\n",
        "            plt.imshow(np.squeeze(sess_results[0][0,:,:,:]))\n",
        "            plt.axis('off')\n",
        "            plt.title('epoch_'+str(iter)+' prep image')\n",
        "            plt.savefig('images/epoch_'+str(iter)+\"c_prep_images.png\")\n",
        "\n",
        "            plt.figure()\n",
        "            plt.imshow(np.squeeze(sess_results[1][0,:,:,:]))\n",
        "            plt.axis('off')\n",
        "            plt.title('epoch_'+str(iter)+\" Hidden Image \")\n",
        "            plt.savefig('images/epoch_'+str(iter)+\"d_hidden_image.png\")\n",
        "\n",
        "            plt.figure()\n",
        "            plt.axis('off')\n",
        "            plt.imshow(np.squeeze(sess_results[2][0,:,:,:]))\n",
        "            plt.title('epoch_'+str(iter)+\" Reveal  Image\")\n",
        "            plt.savefig('images/epoch_'+str(iter)+\"e_reveal_images.png\")\n",
        "\n",
        "            plt.close('all')\n",
        "            print('\\n--------------------\\n')\n",
        "\n",
        "        if iter == num_epoch-1:\n",
        "            \n",
        "            for final in range(len(s_images)):\n",
        "                current_batch_s = np.expand_dims(s_images[final,:,:,:],0)\n",
        "                current_batch_c = np.expand_dims(c_images[final,:,:,:],0)\n",
        "                sess_results = sess.run([prep_layer5,hide_layer5,reve_layer5],feed_dict={Secret:current_batch_s,Cover:current_batch_c})\n",
        "\n",
        "                plt.figure()\n",
        "                plt.imshow(np.squeeze(current_batch_s[0,:,:,:]))\n",
        "                plt.axis('off')\n",
        "                plt.title('epoch_'+str(final)+' Secret')\n",
        "                plt.savefig('gif/epoch_'+str(final)+\"a_secret.png\")\n",
        "\n",
        "                plt.figure()\n",
        "                plt.imshow(np.squeeze(current_batch_c[0,:,:,:]))\n",
        "                plt.axis('off')\n",
        "                plt.title('epoch_'+str(final)+' cover')\n",
        "                plt.savefig('gif/epoch_'+str(final)+\"b_cover.png\")\n",
        "\n",
        "                plt.figure()\n",
        "                plt.imshow(np.squeeze(sess_results[0][0,:,:,:]))\n",
        "                plt.axis('off')\n",
        "                plt.title('epoch_'+str(final)+' prep image')\n",
        "                plt.savefig('gif/epoch_'+str(final)+\"c_prep_images.png\")\n",
        "\n",
        "                plt.figure()\n",
        "                plt.imshow(np.squeeze(sess_results[1][0,:,:,:]))\n",
        "                plt.axis('off')\n",
        "                plt.title('epoch_'+str(final)+\" Hidden Image \")\n",
        "                plt.savefig('gif/epoch_'+str(final)+\"d_hidden_image.png\")\n",
        "\n",
        "                plt.figure()\n",
        "                plt.axis('off')\n",
        "                plt.imshow(np.squeeze(sess_results[2][0,:,:,:]))\n",
        "                plt.title('epoch_'+str(final)+\" Reveal  Image\")\n",
        "                plt.savefig('gif/epoch_'+str(final)+\"e_reveal_images.png\")\n",
        "\n",
        "                plt.close('all')\n",
        "# -- end code --"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}